{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWAqS/tASfP8ddiHWe2Ded",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadiaCopello/Spatial_Analysis_of_Peru_Protected_Areas/blob/main/PREGUNTA_2_Y_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests rasterio numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oSrXR6iRvce",
        "outputId": "39c529ae-10e0-49d3-fd91-ec4124b61b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (1.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.2.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "# Credenciales del Earthdata\n",
        "USERNAME = 'nadiajc'\n",
        "PASSWORD = 'zz4j^z2Sj-FUrwn'\n",
        "\n",
        "# Establezco un directorio de salida\n",
        "output_dir = 'MODIS_MOD44B_2024'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Averigué que tiles son los de Perú\n",
        "tiles = ['h09v09', 'h09v10', 'h10v08', 'h10v09', 'h10v10', 'h11v09', 'h11v10']\n",
        "\n",
        "# Pongo el año que me piden, es decir 2024.\n",
        "year = 2024\n",
        "doy = 1  # Día 1 del año\n",
        "date_str = f'{year}{doy:03d}'\n",
        "\n",
        "# URL base\n",
        "base_url = f'https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/61/MOD44B/2024/'\n",
        "\n",
        "# Sesión con autenticación\n",
        "session = requests.Session()\n",
        "session.auth = (USERNAME, PASSWORD)\n",
        "\n",
        "for tile in tiles:\n",
        "    filename = f'MOD44B.A{date_str}.{tile}.061.*.hdf'\n",
        "    response = session.get(base_url)\n",
        "    if response.status_code == 200:\n",
        "        # Buscar el archivo que coincide con el tile\n",
        "        for line in response.text.split('\\n'):\n",
        "            if tile in line and '.hdf' in line:\n",
        "                start = line.find('MOD44B')\n",
        "                end = line.find('.hdf') + 4\n",
        "                hdf_filename = line[start:end]\n",
        "                file_url = base_url + hdf_filename\n",
        "                output_path = os.path.join(output_dir, hdf_filename)\n",
        "                if not os.path.exists(output_path):\n",
        "                    print(f'Descargando {hdf_filename}...')\n",
        "                    r = session.get(file_url, stream=True)\n",
        "                    with open(output_path, 'wb') as f:\n",
        "                        for chunk in r.iter_content(chunk_size=8192):\n",
        "                            f.write(chunk)\n",
        "    else:\n",
        "        print(f'Error al acceder a {base_url}')\n"
      ],
      "metadata": {
        "id": "pZjD23eiR7ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez descargados los archivos HDF, necesito extraer el subdataset Percent_Tree_Cover y reproyectarlo al sistema de coordenadas EPSG:4326."
      ],
      "metadata": {
        "id": "eHox8PmtSPN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
        "import numpy as np\n",
        "\n",
        "# Lista de archivos HDF descargados\n",
        "hdf_files = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith('.hdf')]\n",
        "\n",
        "# Directorio para los archivos TIFF reproyectados\n",
        "tiff_dir = 'MODIS_TIFF'\n",
        "os.makedirs(tiff_dir, exist_ok=True)\n",
        "\n",
        "for hdf_file in hdf_files:\n",
        "    with rasterio.open(f'HDF4_EOS:EOS_GRID:\"{hdf_file}\":MOD_Grid_Tree_Cover:Percent_Tree_Cover') as src:\n",
        "        # Reproyectar a EPSG:4326\n",
        "        dst_crs = 'EPSG:4326'\n",
        "        transform, width, height = calculate_default_transform(\n",
        "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
        "        kwargs = src.meta.copy()\n",
        "        kwargs.update({\n",
        "            'crs': dst_crs,\n",
        "            'transform': transform,\n",
        "            'width': width,\n",
        "            'height': height\n",
        "        })\n",
        "\n",
        "        tile_name = os.path.basename(hdf_file).replace('.hdf', '.tif')\n",
        "        output_tiff = os.path.join(tiff_dir, tile_name)\n",
        "\n",
        "        with rasterio.open(output_tiff, 'w', **kwargs) as dst:\n",
        "            for i in range(1, src.count + 1):\n",
        "                reproject(\n",
        "                    source=rasterio.band(src, i),\n",
        "                    destination=rasterio.band(dst, i),\n",
        "                    src_transform=src.transform,\n",
        "                    src_crs=src.crs,\n",
        "                    dst_transform=transform,\n",
        "                    dst_crs=dst_crs,\n",
        "                    resampling=Resampling.nearest)\n"
      ],
      "metadata": {
        "id": "iYc3SFa6SRM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rasterio.merge import merge\n",
        "import glob\n",
        "\n",
        "# Lista de archivos TIFF reproyectados\n",
        "tiff_files = glob.glob(os.path.join(tiff_dir, '*.tif'))\n",
        "\n",
        "# Abro los archivos\n",
        "src_files_to_mosaic = []\n",
        "for fp in tiff_files:\n",
        "    src = rasterio.open(fp)\n",
        "    src_files_to_mosaic.append(src)\n",
        "\n",
        "# Creo el mosaico\n",
        "mosaic, out_trans = merge(src_files_to_mosaic)\n",
        "\n",
        "# Actualizo los metadatos\n",
        "out_meta = src.meta.copy()\n",
        "out_meta.update({\n",
        "    'height': mosaic.shape[1],\n",
        "    'width': mosaic.shape[2],\n",
        "    'transform': out_trans,\n",
        "    'crs': 'EPSG:4326'\n",
        "})\n",
        "\n",
        "# Para guardar el mosaico\n",
        "mosaic_path = 'vcf_2024_peru.tif'\n",
        "with rasterio.open(mosaic_path, 'w', **out_meta) as dest:\n",
        "    dest.write(mosaic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "h0XkYafySiil",
        "outputId": "4477e70a-3099-4524-9a37-96c69930f4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-c71aa779a082>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Crear el mosaico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmosaic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_files_to_mosaic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Actualizar los metadatos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rasterio/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(sources, bounds, res, nodata, dtype, precision, indexes, output_count, resampling, method, target_aligned_pixels, mem_limit, use_highest_res, masked, dst_path, dst_kwds)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# Create a dataset_opener object to use in several places in this function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mdataset_opener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UDt2VaNmS6PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pregunta 3\n"
      ],
      "metadata": {
        "id": "utYSHm0tS68Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis de Zonas de Amortiguamiento para Áreas Protegidas\n",
        "# Análisis de efectos de borde en cobertura forestal\n",
        "\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import Point, Polygon\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# CARGAR DATOS\n",
        "\n",
        "def cargar_datos():\n",
        "    \"\"\"\n",
        "    Carga los datos necesarios para el análisis\n",
        "    \"\"\"\n",
        "    print(\" Cargando datos\")\n",
        "\n",
        "    # Cargar shapefile de las áreas protegidas\n",
        "    # voy a suponer que tengo un archivo shapefile con las áreas protegidas\n",
        "    try:\n",
        "        areas_protegidas = gpd.read_file(\"areas_protegidas.shp\")\n",
        "        print(f\" Áreas protegidas cargadas: {len(areas_protegidas)} polígonos\")\n",
        "    except:\n",
        "        print(\" No se encontró el archivo. Creando datos de ejemplo...\")\n",
        "        # Creo datos de ejemplo si no existe el archivo\n",
        "        areas_protegidas = crear_datos_ejemplo()\n",
        "\n",
        "    # Cargar ráster de cobertura forestal\n",
        "    # también asumo que un archivo raster con porcentaje de cobertura arbórea\n",
        "    try:\n",
        "        with rasterio.open(\"cobertura_forestal.tif\") as src:\n",
        "            forest_data = src.read(1)\n",
        "            forest_profile = src.profile\n",
        "        print(\" Ráster de cobertura forestal cargado\")\n",
        "    except:\n",
        "        print(\" No se encontró el ráster. Creando datos simulados...\")\n",
        "        forest_data, forest_profile = crear_raster_ejemplo()\n",
        "\n",
        "    return areas_protegidas, forest_data, forest_profile\n",
        "\n",
        "def crear_datos_ejemplo():\n",
        "    \"\"\"\n",
        "    Crea datos de ejemplo para demostración\n",
        "    \"\"\"\n",
        "    # Creo los polígonos de ejemplo (áreas protegidas ficticias)\n",
        "    polygons = []\n",
        "    for i in range(5):\n",
        "        # Coordenadas aleatorias (ajusta según tu región de interés)\n",
        "        center_lon = -75.0 + i * 0.1\n",
        "        center_lat = -10.0 + i * 0.1\n",
        "\n",
        "        # Creo polígono cuadrado de ~5km x 5km\n",
        "        size = 0.045  # aprox 5km en grados\n",
        "        coords = [\n",
        "            (center_lon - size, center_lat - size),\n",
        "            (center_lon + size, center_lat - size),\n",
        "            (center_lon + size, center_lat + size),\n",
        "            (center_lon - size, center_lat + size),\n",
        "            (center_lon - size, center_lat - size)\n",
        "        ]\n",
        "\n",
        "        polygons.append({\n",
        "            'id_parque': f'PA_{i+1}',\n",
        "            'nombre': f'Área Protegida {i+1}',\n",
        "            'geometry': Polygon(coords)\n",
        "        })\n",
        "\n",
        "    return gpd.GeoDataFrame(polygons, crs='EPSG:4326')\n",
        "\n",
        "def crear_raster_ejemplo():\n",
        "    \"\"\"\n",
        "    Crea un ráster de ejemplo con datos simulados de cobertura forestal\n",
        "    \"\"\"\n",
        "    # Creo una grilla de ejemplo\n",
        "    height, width = 1000, 1000\n",
        "\n",
        "    # Simulo la cobertura forestal (valores entre 0-100%)\n",
        "    np.random.seed(42)\n",
        "    forest_cover = np.random.beta(2, 2, (height, width)) * 100\n",
        "\n",
        "    # Pongo la configuración del ráster\n",
        "    profile = {\n",
        "        'driver': 'GTiff',\n",
        "        'dtype': 'float32',\n",
        "        'nodata': -9999,\n",
        "        'width': width,\n",
        "        'height': height,\n",
        "        'count': 1,\n",
        "        'crs': 'EPSG:4326',\n",
        "        'transform': rasterio.transform.from_bounds(\n",
        "            -76, -11, -74, -9, width, height\n",
        "        )\n",
        "    }\n",
        "\n",
        "    return forest_cover.astype('float32'), profile\n",
        "\n",
        "\n",
        "# GENERAR ZONAS DE AMORTIGUAMIENTO\n",
        "\n",
        "def crear_buffers(geometria, ancho_km):\n",
        "    \"\"\"\n",
        "    Crea buffers interno y externo para una geometría dada\n",
        "\n",
        "    Args:\n",
        "        geometria: Polígono de área protegida\n",
        "        ancho_km: Ancho del buffer en kilómetros\n",
        "\n",
        "    Returns:\n",
        "        buffer_interno, buffer_externo: Geometrías de los buffers\n",
        "    \"\"\"\n",
        "    # Converto km a grados (aproximación: 1 grado ≈ 111 km)\n",
        "    ancho_grados = ancho_km / 111.0\n",
        "\n",
        "    # Y Buffer negativo (interno) - erosión\n",
        "    buffer_interno = geometria.buffer(-ancho_grados)\n",
        "\n",
        "    # Y  Buffer positivo (externo) - dilatación\n",
        "    buffer_total = geometria.buffer(ancho_grados)\n",
        "\n",
        "    # Y Buffer exterior = buffer total - geometría original\n",
        "    buffer_externo = buffer_total.difference(geometria)\n",
        "\n",
        "    return buffer_interno, buffer_externo\n",
        "\n",
        "def procesar_todos_buffers(areas_protegidas, anchos_km):\n",
        "    \"\"\"\n",
        "    Procesa todos los buffers para todas las áreas protegidas\n",
        "\n",
        "    Args:\n",
        "        areas_protegidas: GeoDataFrame con áreas protegidas\n",
        "        anchos_km: Lista de anchos de buffer en km\n",
        "\n",
        "    Returns:\n",
        "        DataFrame con todas las combinaciones de buffers\n",
        "    \"\"\"\n",
        "    print(\"\\n Generando zonas de amortiguamiento...\")\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    for idx, area in areas_protegidas.iterrows():\n",
        "        id_parque = area['id_parque']\n",
        "        geometria = area['geometry']\n",
        "\n",
        "        print(f\"Procesando {id_parque}...\")\n",
        "\n",
        "        for ancho in anchos_km:\n",
        "            try:\n",
        "                buffer_interno, buffer_externo = crear_buffers(geometria, ancho)\n",
        "\n",
        "                # Es importante verificar que los buffers son válidos\n",
        "                if buffer_interno.is_empty or buffer_externo.is_empty:\n",
        "                    print(f\"Buffer vacío para {id_parque} con {ancho}km\")\n",
        "                    continue\n",
        "\n",
        "                # Agrego buffer interno\n",
        "                resultados.append({\n",
        "                    'id_parque': id_parque,\n",
        "                    'buffer_km': ancho,\n",
        "                    'dentro_fuera': 'interno',\n",
        "                    'geometry': buffer_interno\n",
        "                })\n",
        "\n",
        "                # Agrego buffer externo\n",
        "                resultados.append({\n",
        "                    'id_parque': id_parque,\n",
        "                    'buffer_km': ancho,\n",
        "                    'dentro_fuera': 'externo',\n",
        "                    'geometry': buffer_externo\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\" Error procesando {id_parque} con {ancho}km: {e}\")\n",
        "                continue\n",
        "\n",
        "    return gpd.GeoDataFrame(resultados, crs=areas_protegidas.crs)\n",
        "\n"
      ],
      "metadata": {
        "id": "lcTvne1wS8yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# AHORA EXTRAER ESTADÍSTICAS ZONALES\n",
        "\n",
        "def extraer_estadisticas_zonales(geometria, raster_data, raster_profile):\n",
        "    \"\"\"\n",
        "    Extrae estadísticas de un ráster dentro de una geometría\n",
        "\n",
        "    Args:\n",
        "        geometria: Geometría para recortar el ráster\n",
        "        raster_data: Array del ráster\n",
        "        raster_profile: Metadatos del ráster\n",
        "\n",
        "    Returns:\n",
        "        dict con estadísticas (media, mediana, std, n_pixeles)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Creo un dataset temporal en memoria\n",
        "        with rasterio.MemoryFile() as memfile:\n",
        "            with memfile.open(**raster_profile) as dataset:\n",
        "                dataset.write(raster_data, 1)\n",
        "\n",
        "                # Recorto el ráster con la geometría\n",
        "                masked_data, _ = mask(dataset, [geometria], crop=True, nodata=-9999)\n",
        "                masked_data = masked_data[0]  # Primera banda\n",
        "\n",
        "                # Elimino valores NoData\n",
        "                valid_data = masked_data[masked_data != -9999]\n",
        "\n",
        "                if len(valid_data) == 0:\n",
        "                    return {\n",
        "                        'media_tc': np.nan,\n",
        "                        'mediana_tc': np.nan,\n",
        "                        'sd_tc': np.nan,\n",
        "                        'n_pixeles': 0\n",
        "                    }\n",
        "\n",
        "                return {\n",
        "                    'media_tc': float(np.mean(valid_data)),\n",
        "                    'mediana_tc': float(np.median(valid_data)),\n",
        "                    'sd_tc': float(np.std(valid_data)),\n",
        "                    'n_pixeles': len(valid_data)\n",
        "                }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error en estadísticas zonales: {e}\")\n",
        "        return {\n",
        "            'media_tc': np.nan,\n",
        "            'mediana_tc': np.nan,\n",
        "            'sd_tc': np.nan,\n",
        "            'n_pixeles': 0\n",
        "        }\n",
        "\n",
        "def procesar_estadisticas_todas_zonas(buffers_gdf, raster_data, raster_profile):\n",
        "    \"\"\"\n",
        "    Procesa estadísticas zonales para todas las zonas de buffer\n",
        "    \"\"\"\n",
        "    print(\"\\n Extrayendo estadísticas zonales...\")\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    for idx, row in buffers_gdf.iterrows():\n",
        "        print(f\"Procesando {row['id_parque']} - {row['buffer_km']}km - {row['dentro_fuera']}\")\n",
        "\n",
        "        stats = extraer_estadisticas_zonales(\n",
        "            row['geometry'], raster_data, raster_profile\n",
        "        )\n",
        "\n",
        "        resultado = {\n",
        "            'id_parque': row['id_parque'],\n",
        "            'buffer_km': row['buffer_km'],\n",
        "            'dentro_fuera': row['dentro_fuera'],\n",
        "            **stats\n",
        "        }\n",
        "\n",
        "        resultados.append(resultado)\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# LUEGO SE HARÁ EL ANÁLISIS DE REGRESIÓN\n",
        "\n",
        "def preparar_datos_regresion(df_estadisticas):\n",
        "    \"\"\"\n",
        "    Prepara los datos para la regresión binaria\n",
        "    \"\"\"\n",
        "    print(\"\\n Preparando datos para regresión...\")\n",
        "\n",
        "    # CreO variable de tratamiento D (1 = interno/dentro, 0 = externo/fuera)\n",
        "    df_regresion = df_estadisticas.copy()\n",
        "    df_regresion['D'] = (df_regresion['dentro_fuera'] == 'interno').astype(int)\n",
        "\n",
        "    # EliminO filas con valores faltantes\n",
        "    df_regresion = df_regresion.dropna(subset=['media_tc', 'n_pixeles'])\n",
        "    df_regresion = df_regresion[df_regresion['n_pixeles'] > 0]\n",
        "\n",
        "    print(f\"Datos para regresión: {len(df_regresion)} observaciones\")\n",
        "\n",
        "    return df_regresion\n",
        "\n",
        "def ejecutar_regresion(df_regresion):\n",
        "    \"\"\"\n",
        "    Ejecuta la regresión binaria ponderada\n",
        "    \"\"\"\n",
        "    print(\"\\n Ejecutando regresión...\")\n",
        "\n",
        "    # Las Variables\n",
        "    X = df_regresion[['D']].values\n",
        "    y = df_regresion['media_tc'].values\n",
        "    pesos = df_regresion['n_pixeles'].values\n",
        "\n",
        "    # Regresión lineal ponderada\n",
        "    modelo = LinearRegression()\n",
        "    modelo.fit(X, y, sample_weight=pesos)\n",
        "\n",
        "    # Predicciones\n",
        "    y_pred = modelo.predict(X)\n",
        "\n",
        "    # Métricas\n",
        "    r2 = r2_score(y, y_pred, sample_weight=pesos)\n",
        "\n",
        "    # Resultados\n",
        "    intercepto = modelo.intercept_\n",
        "    coef_D = modelo.coef_[0]\n",
        "\n",
        "    print(f\"Intercepto (β₀): {intercepto:.4f}\")\n",
        "    print(f\"Coeficiente D (β₁): {coef_D:.4f}\")\n",
        "    print(f\"R² ponderado: {r2:.4f}\")\n",
        "\n",
        "    # Interpretación\n",
        "    print(f\"\\n Interpretación:\")\n",
        "    print(f\"• Cobertura forestal promedio FUERA de áreas protegidas: {intercepto:.2f}%\")\n",
        "    print(f\"• Diferencia DENTRO vs FUERA: {coef_D:.2f} puntos porcentuales\")\n",
        "\n",
        "    if coef_D > 0:\n",
        "        print(f\"• Las áreas protegidas tienen MAYOR cobertura forestal (+{coef_D:.2f}%)\")\n",
        "    else:\n",
        "        print(f\"• Las áreas protegidas tienen MENOR cobertura forestal ({coef_D:.2f}%)\")\n",
        "\n",
        "    return {\n",
        "        'modelo': modelo,\n",
        "        'intercepto': intercepto,\n",
        "        'coef_D': coef_D,\n",
        "        'r2': r2,\n",
        "        'n_obs': len(df_regresion)\n",
        "    }\n",
        "\n",
        "\n",
        "# LA FUNCIÓN PRINCIPAL\n",
        "def analisis_completo():\n",
        "    \"\"\"\n",
        "    Ejecuta el análisis completo de zonas de amortiguamiento\n",
        "    \"\"\"\n",
        "    print(\" INICIANDO ANÁLISIS DE ZONAS DE AMORTIGUAMIENTO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. CargO datos\n",
        "    areas_protegidas, forest_data, forest_profile = cargar_datos()\n",
        "\n",
        "    # 2. Defino anchos de buffer\n",
        "    anchos_km = [5, 10, 20, 25]\n",
        "\n",
        "    # 3. Genero los buffers\n",
        "    buffers_gdf = procesar_todos_buffers(areas_protegidas, anchos_km)\n",
        "    print(f\" Generados {len(buffers_gdf)} buffers\")\n",
        "\n",
        "    # 4. Extraigo  estadísticas zonales\n",
        "    df_estadisticas = procesar_estadisticas_todas_zonas(\n",
        "        buffers_gdf, forest_data, forest_profile\n",
        "    )\n",
        "\n",
        "    # 5. Guardo resultados en CSV\n",
        "    archivo_csv = \"resultados_buffers.csv\"\n",
        "    df_estadisticas.to_csv(archivo_csv, index=False)\n",
        "    print(f\"✅ Resultados guardados en: {archivo_csv}\")\n",
        "\n",
        "    # 6. Muestro la muestra de resultados...valga la redundancia\n",
        "    print(f\"\\n Muestra de resultados:\")\n",
        "    print(df_estadisticas.head(10).to_string())\n",
        "\n",
        "    # 7. Análisis de regresión\n",
        "    df_regresion = preparar_datos_regresion(df_estadisticas)\n",
        "    resultados_regresion = ejecutar_regresion(df_regresion)\n",
        "\n",
        "    # 8. Visualización\n",
        "    crear_visualizaciones(df_estadisticas, df_regresion)\n",
        "\n",
        "    print(\"\\n ANÁLISIS COMPLETADO\")\n",
        "    return df_estadisticas, resultados_regresion\n",
        "\n",
        "def crear_visualizaciones(df_estadisticas, df_regresion):\n",
        "    \"\"\"\n",
        "    Crea visualizaciones de los resultados\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "    # Gráfico 1: Cobertura promedio por buffer y tipo\n",
        "    ax1 = axes[0, 0]\n",
        "    df_pivot = df_estadisticas.pivot_table(\n",
        "        values='media_tc',\n",
        "        index='buffer_km',\n",
        "        columns='dentro_fuera',\n",
        "        aggfunc='mean'\n",
        "    )\n",
        "    df_pivot.plot(kind='bar', ax=ax1)\n",
        "    ax1.set_title('Cobertura Forestal Promedio por Zona')\n",
        "    ax1.set_ylabel('% Cobertura Arbórea')\n",
        "    ax1.legend(title='Zona')\n",
        "\n",
        "    # Gráfico 2: Distribución de cobertura\n",
        "    ax2 = axes[0, 1]\n",
        "    df_estadisticas[df_estadisticas['dentro_fuera'] == 'interno']['media_tc'].hist(\n",
        "        alpha=0.7, label='Interno', bins=20, ax=ax2\n",
        "    )\n",
        "    df_estadisticas[df_estadisticas['dentro_fuera'] == 'externo']['media_tc'].hist(\n",
        "        alpha=0.7, label='Externo', bins=20, ax=ax2\n",
        "    )\n",
        "    ax2.set_title('Distribución de Cobertura Forestal')\n",
        "    ax2.set_xlabel('% Cobertura Arbórea')\n",
        "    ax2.legend()\n",
        "\n",
        "    # Gráfico 3: Regresión\n",
        "    ax3 = axes[1, 0]\n",
        "    interno = df_regresion[df_regresion['D'] == 1]['media_tc']\n",
        "    externo = df_regresion[df_regresion['D'] == 0]['media_tc']\n",
        "\n",
        "    ax3.scatter([0] * len(externo), externo, alpha=0.6, label='Externo', s=30)\n",
        "    ax3.scatter([1] * len(interno), interno, alpha=0.6, label='Interno', s=30)\n",
        "\n",
        "    # Línea de regresión\n",
        "    medias = [externo.mean(), interno.mean()]\n",
        "    ax3.plot([0, 1], medias, 'r-', linewidth=2, label='Regresión')\n",
        "\n",
        "    ax3.set_"
      ],
      "metadata": {
        "id": "fm0a9V1iUJW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INTENTO DEL CREDITO EXTRA\n"
      ],
      "metadata": {
        "id": "oHQE2uCmVSk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis de Regresión Discontinua (RD) a Nivel de Píxel\n",
        "#CREDITO EXTRA\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rasterio.features import rasterize\n",
        "from rasterio.transform import rowcol, xy\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import seaborn as sns\n",
        "from shapely.geometry import Point\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# PREPARO DATOS Y MÁSCARAS\n",
        "\n",
        "def crear_datos_ejemplo():\n",
        "    \"\"\"\n",
        "    Crea datos de ejemplo para demostrar el análisis RD\n",
        "    \"\"\"\n",
        "    print(\" Creando datos de ejemplo...\")\n",
        "\n",
        "    # Creo área protegida de ejemplo\n",
        "    from shapely.geometry import Polygon\n",
        "\n",
        "    # Área protegida rectangular\n",
        "    area_protegida = Polygon([\n",
        "        (-75.2, -10.2),\n",
        "        (-74.8, -10.2),\n",
        "        (-74.8, -9.8),\n",
        "        (-75.2, -9.8),\n",
        "        (-75.2, -10.2)\n",
        "    ])\n",
        "\n",
        "    gdf = gpd.GeoDataFrame([{'id': 'PA_1', 'geometry': area_protegida}], crs='EPSG:4326')\n",
        "\n",
        "    # Creo ráster de cobertura forestal simulado\n",
        "    height, width = 400, 400\n",
        "\n",
        "    # Coordenadas del ráster\n",
        "    bounds = (-75.4, -10.4, -74.6, -9.6)\n",
        "    transform = rasterio.transform.from_bounds(*bounds, width, height)\n",
        "\n",
        "    # Simulo cobertura forestal con efecto de borde\n",
        "    np.random.seed(42)\n",
        "    x = np.linspace(-75.4, -74.6, width)\n",
        "    y = np.linspace(-10.4, -9.6, height)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "\n",
        "    # Creo efecto de gradiente hacia el área protegida\n",
        "    center_x, center_y = -75.0, -10.0\n",
        "    distance_to_center = np.sqrt((X - center_x)**2 + (Y - center_y)**2)\n",
        "\n",
        "    # Cobertura base con efecto espacial\n",
        "    base_coverage = 60 + 30 * np.exp(-distance_to_center * 50)\n",
        "\n",
        "    # Agrego ruido\n",
        "    noise = np.random.normal(0, 10, (height, width))\n",
        "    forest_coverage = np.clip(base_coverage + noise, 0, 100)\n",
        "\n",
        "    profile = {\n",
        "        'driver': 'GTiff',\n",
        "        'dtype': 'float32',\n",
        "        'nodata': -9999,\n",
        "        'width': width,\n",
        "        'height': height,\n",
        "        'count': 1,\n",
        "        'crs': 'EPSG:4326',\n",
        "        'transform': transform\n",
        "    }\n",
        "\n",
        "    return gdf, forest_coverage.astype('float32'), profile\n",
        "\n",
        "def cargar_datos_reales(shapefile_path, raster_path):\n",
        "    \"\"\"\n",
        "    Carga datos reales si están disponibles\n",
        "    \"\"\"\n",
        "    try:\n",
        "        gdf = gpd.read_file(shapefile_path)\n",
        "        with rasterio.open(raster_path) as src:\n",
        "            forest_data = src.read(1)\n",
        "            profile = src.profile\n",
        "        print(\" Datos reales cargados\")\n",
        "        return gdf, forest_data, profile\n",
        "    except:\n",
        "        print(\" Usando datos de ejemplo\")\n",
        "        return crear_datos_ejemplo()\n",
        "\n",
        "\n",
        "# CALCULO DISTANCIA AL LÍMITE\n",
        "\n",
        "def crear_mascara_area_protegida(gdf, raster_profile):\n",
        "    \"\"\"\n",
        "    Crea máscara binaria del área protegida en el ráster\n",
        "    \"\"\"\n",
        "    print(\" Creando máscara de área protegida...\")\n",
        "\n",
        "    # Rasterizo el polígono\n",
        "    shapes = [(geom, 1) for geom in gdf.geometry]\n",
        "\n",
        "    mask = rasterize(\n",
        "        shapes=shapes,\n",
        "        out_shape=(raster_profile['height'], raster_profile['width']),\n",
        "        transform=raster_profile['transform'],\n",
        "        fill=0,\n",
        "        dtype='uint8'\n",
        "    )\n",
        "\n",
        "    return mask.astype(bool)\n",
        "\n",
        "def calcular_distancia_al_limite(mask, transform):\n",
        "    \"\"\"\n",
        "    Calcula la distancia de cada píxel al límite del área protegida\n",
        "\n",
        "    Args:\n",
        "        mask: Máscara binaria (True = dentro, False = fuera)\n",
        "        transform: Transformación georreferenciada del ráster\n",
        "\n",
        "    Returns:\n",
        "        distance_array: Array con distancias (+ = interno, - = externo)\n",
        "    \"\"\"\n",
        "    print(\" Calculando distancias al límite...\")\n",
        "\n",
        "    # Distancia euclidiana desde el interior hacia el borde\n",
        "    dist_interior = distance_transform_edt(mask)\n",
        "\n",
        "    # Distancia euclidiana desde el exterior hacia el borde\n",
        "    dist_exterior = distance_transform_edt(~mask)\n",
        "\n",
        "    # Combino: positivo = interno, negativo = externo\n",
        "    distance_array = np.where(mask, dist_interior, -dist_exterior)\n",
        "\n",
        "    # Convierto píxeles a metros (aproximación)\n",
        "    pixel_size_degrees = abs(transform[0])  # Tamaño de píxel en grados\n",
        "    meters_per_degree = 111320  # Aproximadamente en el ecuador\n",
        "    pixel_size_meters = pixel_size_degrees * meters_per_degree\n",
        "\n",
        "    distance_meters = distance_array * pixel_size_meters\n",
        "\n",
        "    return distance_meters\n",
        "\n",
        "# PREPARO LOS DATOS A NIVEL DE PÍXEL\n",
        "\n",
        "def extraer_datos_buffer_25km(distance_array, forest_data, buffer_km=25):\n",
        "    \"\"\"\n",
        "    Extrae datos de píxeles dentro del buffer de 25km del límite\n",
        "    \"\"\"\n",
        "    print(f\"🎯 Extrayendo píxeles dentro de {buffer_km}km del límite...\")\n",
        "\n",
        "    buffer_meters = buffer_km * 1000\n",
        "\n",
        "    # Máscara para píxeles dentro del buffer\n",
        "    buffer_mask = np.abs(distance_array) <= buffer_meters\n",
        "\n",
        "    # Extraigo datos válidos\n",
        "    valid_mask = buffer_mask & (forest_data != -9999) & (~np.isnan(forest_data))\n",
        "\n",
        "    distances = distance_array[valid_mask]\n",
        "    forest_values = forest_data[valid_mask]\n",
        "\n",
        "    # Creo DataFrame\n",
        "    df_pixels = pd.DataFrame({\n",
        "        'distance_m': distances,\n",
        "        'forest_cover': forest_values,\n",
        "        'inside': distances >= 0\n",
        "    })\n",
        "\n",
        "    print(f\"  Extraídos {len(df_pixels):,} píxeles válidos\")\n",
        "    print(f\"   - Internos: {(df_pixels['inside']).sum():,}\")\n",
        "    print(f\"   - Externos: {(~df_pixels['inside']).sum():,}\")\n",
        "\n",
        "    return df_pixels\n",
        "\n",
        "# HAGO EL ANÁLISIS DE REGRESIÓN DISCONTINUA\n",
        "\n",
        "def ejecutar_rd_analysis(df_pixels, bandwidth_m=5000, poly_degree=2):\n",
        "    \"\"\"\n",
        "    Ejecuta análisis de Regresión Discontinua\n",
        "\n",
        "    Args:\n",
        "        df_pixels: DataFrame con datos de píxeles\n",
        "        bandwidth_m: Ancho de banda alrededor del límite (metros)\n",
        "        poly_degree: Grado del polinomio para controles flexibles\n",
        "    \"\"\"\n",
        "    print(f\"\\n Ejecutando Regresión Discontinua...\")\n",
        "    print(f\"   - Ancho de banda: ±{bandwidth_m/1000:.1f}km\")\n",
        "    print(f\"   - Grado polinomial: {poly_degree}\")\n",
        "\n",
        "    # Filtro datos dentro del ancho de banda\n",
        "    df_rd = df_pixels[np.abs(df_pixels['distance_m']) <= bandwidth_m].copy()\n",
        "\n",
        "    if len(df_rd) == 0:\n",
        "        print(\" No hay datos dentro del ancho de banda\")\n",
        "        return None\n",
        "\n",
        "    # Normalizo las distancia (dividir por 1000 para trabajar en km)\n",
        "    df_rd['distance_km'] = df_rd['distance_m'] / 1000\n",
        "    df_rd['treatment'] = df_rd['inside'].astype(int)\n",
        "\n",
        "    # Centrar distancia en el límite\n",
        "    df_rd['distance_centered'] = df_rd['distance_km']\n",
        "\n",
        "    # Creo variables polinomiales\n",
        "    X_vars = []\n",
        "\n",
        "    # Variable de tratamiento (discontinuidad)\n",
        "    X_vars.append(df_rd['treatment'].values.reshape(-1, 1))\n",
        "\n",
        "    # Controles polinomiales de distancia\n",
        "    for degree in range(1, poly_degree + 1):\n",
        "        X_vars.append((df_rd['distance_centered'] ** degree).values.reshape(-1, 1))\n",
        "\n",
        "    # Interacciones tratamiento × distancia\n",
        "    for degree in range(1, poly_degree + 1):\n",
        "        interaction = (df_rd['treatment'] * (df_rd['distance_centered'] ** degree)).values.reshape(-1, 1)\n",
        "        X_vars.append(interaction)\n",
        "\n",
        "    # Combino todas las variables\n",
        "    X = np.hstack(X_vars)\n",
        "    y = df_rd['forest_cover'].values\n",
        "\n",
        "    # Regresión\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predicciones\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # El coeficiente de tratamiento es el primero\n",
        "    rd_effect = model.coef_[0]\n",
        "    intercept = model.intercept_\n",
        "\n",
        "    # R²\n",
        "    ss_res = np.sum((y - y_pred) ** 2)\n",
        "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    # Estadísticas descriptivas\n",
        "    stats = {\n",
        "        'n_total': len(df_rd),\n",
        "        'n_inside': df_rd['treatment'].sum(),\n",
        "        'n_outside': len(df_rd) - df_rd['treatment'].sum(),\n",
        "        'mean_inside': df_rd[df_rd['inside']]['forest_cover'].mean(),\n",
        "        'mean_outside': df_rd[~df_rd['inside']]['forest_cover'].mean(),\n",
        "        'rd_effect': rd_effect,\n",
        "        'intercept': intercept,\n",
        "        'r2': r2,\n",
        "        'bandwidth_km': bandwidth_m / 1000\n",
        "    }\n",
        "\n",
        "    print(f\"\\n RESULTADOS DE REGRESIÓN DISCONTINUA:\")\n",
        "    print(f\"   • Observaciones: {stats['n_total']:,}\")\n",
        "    print(f\"   • Efecto RD (β₁): {rd_effect:.3f} puntos porcentuales\")\n",
        "    print(f\"   • Cobertura en el límite (exterior): {intercept:.2f}%\")\n",
        "    print(f\"   • R²: {r2:.3f}\")\n",
        "    print(f\"   • Media interna: {stats['mean_inside']:.2f}%\")\n",
        "    print(f\"   • Media externa: {stats['mean_outside']:.2f}%\")\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'data': df_rd,\n",
        "        'stats': stats,\n",
        "        'X': X,\n",
        "        'y': y,\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "\n",
        "# LUEGO LAS VISUALIZACIONES\n",
        "\n",
        "def crear_graficos_rd(rd_results, df_pixels):\n",
        "    \"\"\"\n",
        "    Crea gráficos de Regresión Discontinua\n",
        "    \"\"\"\n",
        "    print(\"\\n Generando gráficos...\")\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "    df_rd = rd_results['data']\n",
        "    stats = rd_results['stats']\n",
        "\n",
        "    # Gráfico 1: RD Plot Principal\n",
        "    ax1 = axes[0, 0]\n",
        "\n",
        "    # Datos agrupados en bins para visualización\n",
        "    bins_inside = np.linspace(0, stats['bandwidth_km'], 20)\n",
        "    bins_outside = np.linspace(-stats['bandwidth_km'], 0, 20)\n",
        "\n",
        "    # Calculo medias por bin\n",
        "    def bin_means(distances, values, bins):\n",
        "        bin_centers = []\n",
        "        bin_means_vals = []\n",
        "        for i in range(len(bins)-1):\n",
        "            mask = (distances >= bins[i]) & (distances < bins[i+1])\n",
        "            if mask.sum() > 0:\n",
        "                bin_centers.append((bins[i] + bins[i+1]) / 2)\n",
        "                bin_means_vals.append(values[mask].mean())\n",
        "        return np.array(bin_centers), np.array(bin_means_vals)\n",
        "\n",
        "    # Datos internos\n",
        "    inside_data = df_rd[df_rd['inside']]\n",
        "    if len(inside_data) > 0:\n",
        "        bin_centers_in, bin_means_in = bin_means(\n",
        "            inside_data['distance_km'], inside_data['forest_cover'], bins_inside\n",
        "        )\n",
        "        ax1.scatter(bin_centers_in, bin_means_in, c='green', s=50, alpha=0.7, label='Interno')\n",
        "\n",
        "    # Datos externos\n",
        "    outside_data = df_rd[~df_rd['inside']]\n",
        "    if len(outside_data) > 0:\n",
        "        bin_centers_out, bin_means_out = bin_means(\n",
        "            outside_data['distance_km'], outside_data['forest_cover'], bins_outside\n",
        "        )\n",
        "        ax1.scatter(bin_centers_out, bin_means_out, c='red', s=50, alpha=0.7, label='Externo')\n",
        "\n",
        "    # Línea de regresión\n",
        "    x_smooth = np.linspace(-stats['bandwidth_km'], stats['bandwidth_km'], 100)\n",
        "\n",
        "    # Predicción para visualización (simplificada)\n",
        "    y_left = stats['intercept'] + 0 * x_smooth[x_smooth < 0]  # Lado externo\n",
        "    y_right = stats['intercept'] + stats['rd_effect'] + 0 * x_smooth[x_smooth >= 0]  # Lado interno\n",
        "\n",
        "    if len(x_smooth[x_smooth < 0]) > 0:\n",
        "        ax1.plot(x_smooth[x_smooth < 0], y_left, 'r-', linewidth=2, alpha=0.8)\n",
        "    if len(x_smooth[x_smooth >= 0]) > 0:\n",
        "        ax1.plot(x_smooth[x_smooth >= 0], y_right, 'g-', linewidth=2, alpha=0.8)\n",
        "\n",
        "    # Línea vertical en el límite\n",
        "    ax1.axvline(x=0, color='black', linestyle='--', alpha=0.5, label='Límite AP')\n",
        "\n",
        "    ax1.set_xlabel('Distancia al Límite (km)')\n",
        "    ax1.set_ylabel('Cobertura Forestal (%)')\n",
        "    ax1.set_title(f'Regresión Discontinua\\nEfecto: {stats[\"rd_effect\"]:.2f} pp')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Gráfico 2: Distribución de distancias\n",
        "    ax2 = axes[0, 1]\n",
        "    df_rd['distance_km'].hist(bins=30, alpha=0.7, ax=ax2)\n",
        "    ax2.axvline(x=0, color='red', linestyle='--', label='Límite')\n",
        "    ax2.set_xlabel('Distancia al Límite (km)')\n",
        "    ax2.set_ylabel('Número de Píxeles')\n",
        "    ax2.set_title('Distribución de Distancias')\n",
        "    ax2.legend()\n",
        "\n",
        "    # Gráfico 3: Cobertura vs Distancia (scatter completo)\n",
        "    ax3 = axes[1, 0]\n",
        "\n",
        "    # Submuestreo para visualización si hay muchos puntos\n",
        "    if len(df_rd) > 5000:\n",
        "        df_sample = df_rd.sample(5000, random_state=42)\n",
        "    else:\n",
        "        df_sample = df_rd\n",
        "\n",
        "    inside_sample = df_sample[df_sample['inside']]\n",
        "    outside_sample = df_sample[~df_sample['inside']]\n",
        "\n",
        "    ax3.scatter(outside_sample['distance_km'], outside_sample['forest_cover'],\n",
        "               c='red', alpha=0.3, s=1, label='Externo')\n",
        "    ax3.scatter(inside_sample['distance_km'], inside_sample['forest_cover'],\n",
        "               c='green', alpha=0.3, s=1, label='Interno')\n",
        "\n",
        "    ax3.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
        "    ax3.set_xlabel('Distancia al Límite (km)')\n",
        "    ax3.set_ylabel('Cobertura Forestal (%)')\n",
        "    ax3.set_title('Datos Individuales por Píxel')\n",
        "    ax3.legend()\n",
        "\n",
        "    # Gráfico 4: Comparación de medias\n",
        "    ax4 = axes[1, 1]\n",
        "\n",
        "    means = [stats['mean_outside'], stats['mean_inside']]\n",
        "    labels = ['Externo', 'Interno']\n",
        "    colors = ['red', 'green']\n",
        "\n",
        "    bars = ax4.bar(labels, means, color=colors, alpha=0.7)\n",
        "    ax4.set_ylabel('Cobertura Forestal Promedio (%)')\n",
        "    ax4.set_title('Comparación de Medias')\n",
        "\n",
        "    # Agrego valores en las barras\n",
        "    for bar, mean in zip(bars, means):\n",
        "        height = bar.get_height()\n",
        "        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                f'{mean:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "    # Línea de diferencia\n",
        "    ax4.annotate('', xy=(0.1, stats['mean_outside']), xytext=(0.9, stats['mean_inside']),\n",
        "                arrowprops=dict(arrowstyle='<->', color='blue', lw=2))\n",
        "    ax4.text(0.5, (stats['mean_inside'] + stats['mean_outside'])/2 + 1,\n",
        "             f'Δ = {stats[\"rd_effect\"]:.2f} pp', ha='center', color='blue', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('rd_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# LA FUNCIÓN PRINCIPAL\n",
        "\n",
        "def analisis_rd_completo(shapefile_path=None, raster_path=None):\n",
        "    \"\"\"\n",
        "    Ejecuta el análisis completo de Regresión Discontinua\n",
        "    \"\"\"\n",
        "    print(\" ANÁLISIS DE REGRESIÓN DISCONTINUA - NIVEL DE PÍXEL\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. Cargo datos\n",
        "    if shapefile_path and raster_path:\n",
        "        gdf, forest_data, profile = cargar_datos_reales(shapefile_path, raster_path)\n",
        "    else:\n",
        "        gdf, forest_data, profile = crear_datos_ejemplo()\n",
        "\n",
        "    # 2. Creo máscara de área protegida\n",
        "    mask = crear_mascara_area_protegida(gdf, profile)\n",
        "\n",
        "    # 3. Calculo distancias al límite\n",
        "    distance_array = calcular_distancia_al_limite(mask, profile['transform'])\n",
        "\n",
        "    # 4. Extraigo datos en buffer de 25km\n",
        "    df_pixels = extraer_datos_buffer_25km(distance_array, forest_data, buffer_km=25)\n",
        "\n",
        "    # 5. Análisis RD con diferentes anchos de banda\n",
        "    print(f\"\\n🔬 PROBANDO DIFERENTES ANCHOS DE BANDA:\")\n",
        "\n",
        "    bandwidths = [2, 5, 10, 15]  # km\n",
        "    rd_results_list = []\n",
        "\n",
        "    for bw_km in bandwidths:\n",
        "        print(f\"\\n--- Ancho de banda: {bw_km}km ---\")\n",
        "        rd_result = ejecutar_rd_analysis(df_pixels, bandwidth_m=bw_km*1000, poly_degree=2)\n",
        "        if rd_result:\n",
        "            rd_results_list.append({\n",
        "                'bandwidth': bw_km,\n",
        "                'effect': rd_result['stats']['rd_effect'],\n",
        "                'r2': rd_result['stats']['r2'],\n",
        "                'n_obs': rd_result['stats']['n_total']\n",
        "            })\n",
        "\n",
        "    # 6. Uso el ancho de banda óptimo (5km por defecto)\n",
        "    rd_final = ejecutar_rd_analysis(df_pixels, bandwidth_m=5000, poly_degree=2)\n",
        "\n",
        "    # 7. Creo visualizaciones\n",
        "    if rd_final:\n",
        "        crear_graficos_rd(rd_final, df_pixels)\n",
        "\n",
        "    # 8. Resumen de resultados\n",
        "    print(f\"\\n RESUMEN DE RESULTADOS:\")\n",
        "    print(\"-\" * 40)\n",
        "    for result in rd_results_list:\n",
        "        print(f\"BW={result['bandwidth']:2d}km: Efecto={result['effect']:+6.2f}pp, \"\n",
        "              f\"R²={result['r2']:.3f}, N={result['n_obs']:,}\")\n",
        "\n",
        "    return {\n",
        "        'distance_array': distance_array,\n",
        "        'df_pixels': df_pixels,\n",
        "        'rd_results': rd_final,\n",
        "        'sensitivity': rd_results_list,\n",
        "        'mask': mask\n",
        "    }\n",
        "\n",
        "# EJECUTO EL ANÁLISIS\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejecutar con datos de ejemplo\n",
        "    resultados = analisis_rd_completo()\n",
        "\n",
        "    # Para usar tus propios datos, descomenta y ajusta:\n",
        "    # resultados = analisis_rd_completo(\n",
        "    #     shapefile_path=\"areas_protegidas.shp\",\n",
        "    #     raster_path=\"cobertura_forestal.tif\"\n",
        "    # )"
      ],
      "metadata": {
        "id": "-VYrKn7ZVYoB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}