{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWAqS/tASfP8ddiHWe2Ded",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadiaCopello/Spatial_Analysis_of_Peru_Protected_Areas/blob/main/PREGUNTA_2_Y_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests rasterio numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oSrXR6iRvce",
        "outputId": "39c529ae-10e0-49d3-fd91-ec4124b61b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (1.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.2.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "# Credenciales del Earthdata\n",
        "USERNAME = 'nadiajc'\n",
        "PASSWORD = 'zz4j^z2Sj-FUrwn'\n",
        "\n",
        "# Establezco un directorio de salida\n",
        "output_dir = 'MODIS_MOD44B_2024'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Averigu√© que tiles son los de Per√∫\n",
        "tiles = ['h09v09', 'h09v10', 'h10v08', 'h10v09', 'h10v10', 'h11v09', 'h11v10']\n",
        "\n",
        "# Pongo el a√±o que me piden, es decir 2024.\n",
        "year = 2024\n",
        "doy = 1  # D√≠a 1 del a√±o\n",
        "date_str = f'{year}{doy:03d}'\n",
        "\n",
        "# URL base\n",
        "base_url = f'https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/61/MOD44B/2024/'\n",
        "\n",
        "# Sesi√≥n con autenticaci√≥n\n",
        "session = requests.Session()\n",
        "session.auth = (USERNAME, PASSWORD)\n",
        "\n",
        "for tile in tiles:\n",
        "    filename = f'MOD44B.A{date_str}.{tile}.061.*.hdf'\n",
        "    response = session.get(base_url)\n",
        "    if response.status_code == 200:\n",
        "        # Buscar el archivo que coincide con el tile\n",
        "        for line in response.text.split('\\n'):\n",
        "            if tile in line and '.hdf' in line:\n",
        "                start = line.find('MOD44B')\n",
        "                end = line.find('.hdf') + 4\n",
        "                hdf_filename = line[start:end]\n",
        "                file_url = base_url + hdf_filename\n",
        "                output_path = os.path.join(output_dir, hdf_filename)\n",
        "                if not os.path.exists(output_path):\n",
        "                    print(f'Descargando {hdf_filename}...')\n",
        "                    r = session.get(file_url, stream=True)\n",
        "                    with open(output_path, 'wb') as f:\n",
        "                        for chunk in r.iter_content(chunk_size=8192):\n",
        "                            f.write(chunk)\n",
        "    else:\n",
        "        print(f'Error al acceder a {base_url}')\n"
      ],
      "metadata": {
        "id": "pZjD23eiR7ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez descargados los archivos HDF, necesito extraer el subdataset Percent_Tree_Cover y reproyectarlo al sistema de coordenadas EPSG:4326."
      ],
      "metadata": {
        "id": "eHox8PmtSPN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
        "import numpy as np\n",
        "\n",
        "# Lista de archivos HDF descargados\n",
        "hdf_files = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith('.hdf')]\n",
        "\n",
        "# Directorio para los archivos TIFF reproyectados\n",
        "tiff_dir = 'MODIS_TIFF'\n",
        "os.makedirs(tiff_dir, exist_ok=True)\n",
        "\n",
        "for hdf_file in hdf_files:\n",
        "    with rasterio.open(f'HDF4_EOS:EOS_GRID:\"{hdf_file}\":MOD_Grid_Tree_Cover:Percent_Tree_Cover') as src:\n",
        "        # Reproyectar a EPSG:4326\n",
        "        dst_crs = 'EPSG:4326'\n",
        "        transform, width, height = calculate_default_transform(\n",
        "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
        "        kwargs = src.meta.copy()\n",
        "        kwargs.update({\n",
        "            'crs': dst_crs,\n",
        "            'transform': transform,\n",
        "            'width': width,\n",
        "            'height': height\n",
        "        })\n",
        "\n",
        "        tile_name = os.path.basename(hdf_file).replace('.hdf', '.tif')\n",
        "        output_tiff = os.path.join(tiff_dir, tile_name)\n",
        "\n",
        "        with rasterio.open(output_tiff, 'w', **kwargs) as dst:\n",
        "            for i in range(1, src.count + 1):\n",
        "                reproject(\n",
        "                    source=rasterio.band(src, i),\n",
        "                    destination=rasterio.band(dst, i),\n",
        "                    src_transform=src.transform,\n",
        "                    src_crs=src.crs,\n",
        "                    dst_transform=transform,\n",
        "                    dst_crs=dst_crs,\n",
        "                    resampling=Resampling.nearest)\n"
      ],
      "metadata": {
        "id": "iYc3SFa6SRM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rasterio.merge import merge\n",
        "import glob\n",
        "\n",
        "# Lista de archivos TIFF reproyectados\n",
        "tiff_files = glob.glob(os.path.join(tiff_dir, '*.tif'))\n",
        "\n",
        "# Abro los archivos\n",
        "src_files_to_mosaic = []\n",
        "for fp in tiff_files:\n",
        "    src = rasterio.open(fp)\n",
        "    src_files_to_mosaic.append(src)\n",
        "\n",
        "# Creo el mosaico\n",
        "mosaic, out_trans = merge(src_files_to_mosaic)\n",
        "\n",
        "# Actualizo los metadatos\n",
        "out_meta = src.meta.copy()\n",
        "out_meta.update({\n",
        "    'height': mosaic.shape[1],\n",
        "    'width': mosaic.shape[2],\n",
        "    'transform': out_trans,\n",
        "    'crs': 'EPSG:4326'\n",
        "})\n",
        "\n",
        "# Para guardar el mosaico\n",
        "mosaic_path = 'vcf_2024_peru.tif'\n",
        "with rasterio.open(mosaic_path, 'w', **out_meta) as dest:\n",
        "    dest.write(mosaic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "h0XkYafySiil",
        "outputId": "4477e70a-3099-4524-9a37-96c69930f4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-c71aa779a082>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Crear el mosaico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmosaic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_files_to_mosaic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Actualizar los metadatos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rasterio/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(sources, bounds, res, nodata, dtype, precision, indexes, output_count, resampling, method, target_aligned_pixels, mem_limit, use_highest_res, masked, dst_path, dst_kwds)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# Create a dataset_opener object to use in several places in this function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mdataset_opener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UDt2VaNmS6PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pregunta 3\n"
      ],
      "metadata": {
        "id": "utYSHm0tS68Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An√°lisis de Zonas de Amortiguamiento para √Åreas Protegidas\n",
        "# An√°lisis de efectos de borde en cobertura forestal\n",
        "\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import Point, Polygon\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# CARGAR DATOS\n",
        "\n",
        "def cargar_datos():\n",
        "    \"\"\"\n",
        "    Carga los datos necesarios para el an√°lisis\n",
        "    \"\"\"\n",
        "    print(\" Cargando datos\")\n",
        "\n",
        "    # Cargar shapefile de las √°reas protegidas\n",
        "    # voy a suponer que tengo un archivo shapefile con las √°reas protegidas\n",
        "    try:\n",
        "        areas_protegidas = gpd.read_file(\"areas_protegidas.shp\")\n",
        "        print(f\" √Åreas protegidas cargadas: {len(areas_protegidas)} pol√≠gonos\")\n",
        "    except:\n",
        "        print(\" No se encontr√≥ el archivo. Creando datos de ejemplo...\")\n",
        "        # Creo datos de ejemplo si no existe el archivo\n",
        "        areas_protegidas = crear_datos_ejemplo()\n",
        "\n",
        "    # Cargar r√°ster de cobertura forestal\n",
        "    # tambi√©n asumo que un archivo raster con porcentaje de cobertura arb√≥rea\n",
        "    try:\n",
        "        with rasterio.open(\"cobertura_forestal.tif\") as src:\n",
        "            forest_data = src.read(1)\n",
        "            forest_profile = src.profile\n",
        "        print(\" R√°ster de cobertura forestal cargado\")\n",
        "    except:\n",
        "        print(\" No se encontr√≥ el r√°ster. Creando datos simulados...\")\n",
        "        forest_data, forest_profile = crear_raster_ejemplo()\n",
        "\n",
        "    return areas_protegidas, forest_data, forest_profile\n",
        "\n",
        "def crear_datos_ejemplo():\n",
        "    \"\"\"\n",
        "    Crea datos de ejemplo para demostraci√≥n\n",
        "    \"\"\"\n",
        "    # Creo los pol√≠gonos de ejemplo (√°reas protegidas ficticias)\n",
        "    polygons = []\n",
        "    for i in range(5):\n",
        "        # Coordenadas aleatorias (ajusta seg√∫n tu regi√≥n de inter√©s)\n",
        "        center_lon = -75.0 + i * 0.1\n",
        "        center_lat = -10.0 + i * 0.1\n",
        "\n",
        "        # Creo pol√≠gono cuadrado de ~5km x 5km\n",
        "        size = 0.045  # aprox 5km en grados\n",
        "        coords = [\n",
        "            (center_lon - size, center_lat - size),\n",
        "            (center_lon + size, center_lat - size),\n",
        "            (center_lon + size, center_lat + size),\n",
        "            (center_lon - size, center_lat + size),\n",
        "            (center_lon - size, center_lat - size)\n",
        "        ]\n",
        "\n",
        "        polygons.append({\n",
        "            'id_parque': f'PA_{i+1}',\n",
        "            'nombre': f'√Årea Protegida {i+1}',\n",
        "            'geometry': Polygon(coords)\n",
        "        })\n",
        "\n",
        "    return gpd.GeoDataFrame(polygons, crs='EPSG:4326')\n",
        "\n",
        "def crear_raster_ejemplo():\n",
        "    \"\"\"\n",
        "    Crea un r√°ster de ejemplo con datos simulados de cobertura forestal\n",
        "    \"\"\"\n",
        "    # Creo una grilla de ejemplo\n",
        "    height, width = 1000, 1000\n",
        "\n",
        "    # Simulo la cobertura forestal (valores entre 0-100%)\n",
        "    np.random.seed(42)\n",
        "    forest_cover = np.random.beta(2, 2, (height, width)) * 100\n",
        "\n",
        "    # Pongo la configuraci√≥n del r√°ster\n",
        "    profile = {\n",
        "        'driver': 'GTiff',\n",
        "        'dtype': 'float32',\n",
        "        'nodata': -9999,\n",
        "        'width': width,\n",
        "        'height': height,\n",
        "        'count': 1,\n",
        "        'crs': 'EPSG:4326',\n",
        "        'transform': rasterio.transform.from_bounds(\n",
        "            -76, -11, -74, -9, width, height\n",
        "        )\n",
        "    }\n",
        "\n",
        "    return forest_cover.astype('float32'), profile\n",
        "\n",
        "\n",
        "# GENERAR ZONAS DE AMORTIGUAMIENTO\n",
        "\n",
        "def crear_buffers(geometria, ancho_km):\n",
        "    \"\"\"\n",
        "    Crea buffers interno y externo para una geometr√≠a dada\n",
        "\n",
        "    Args:\n",
        "        geometria: Pol√≠gono de √°rea protegida\n",
        "        ancho_km: Ancho del buffer en kil√≥metros\n",
        "\n",
        "    Returns:\n",
        "        buffer_interno, buffer_externo: Geometr√≠as de los buffers\n",
        "    \"\"\"\n",
        "    # Converto km a grados (aproximaci√≥n: 1 grado ‚âà 111 km)\n",
        "    ancho_grados = ancho_km / 111.0\n",
        "\n",
        "    # Y Buffer negativo (interno) - erosi√≥n\n",
        "    buffer_interno = geometria.buffer(-ancho_grados)\n",
        "\n",
        "    # Y  Buffer positivo (externo) - dilataci√≥n\n",
        "    buffer_total = geometria.buffer(ancho_grados)\n",
        "\n",
        "    # Y Buffer exterior = buffer total - geometr√≠a original\n",
        "    buffer_externo = buffer_total.difference(geometria)\n",
        "\n",
        "    return buffer_interno, buffer_externo\n",
        "\n",
        "def procesar_todos_buffers(areas_protegidas, anchos_km):\n",
        "    \"\"\"\n",
        "    Procesa todos los buffers para todas las √°reas protegidas\n",
        "\n",
        "    Args:\n",
        "        areas_protegidas: GeoDataFrame con √°reas protegidas\n",
        "        anchos_km: Lista de anchos de buffer en km\n",
        "\n",
        "    Returns:\n",
        "        DataFrame con todas las combinaciones de buffers\n",
        "    \"\"\"\n",
        "    print(\"\\n Generando zonas de amortiguamiento...\")\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    for idx, area in areas_protegidas.iterrows():\n",
        "        id_parque = area['id_parque']\n",
        "        geometria = area['geometry']\n",
        "\n",
        "        print(f\"Procesando {id_parque}...\")\n",
        "\n",
        "        for ancho in anchos_km:\n",
        "            try:\n",
        "                buffer_interno, buffer_externo = crear_buffers(geometria, ancho)\n",
        "\n",
        "                # Es importante verificar que los buffers son v√°lidos\n",
        "                if buffer_interno.is_empty or buffer_externo.is_empty:\n",
        "                    print(f\"Buffer vac√≠o para {id_parque} con {ancho}km\")\n",
        "                    continue\n",
        "\n",
        "                # Agrego buffer interno\n",
        "                resultados.append({\n",
        "                    'id_parque': id_parque,\n",
        "                    'buffer_km': ancho,\n",
        "                    'dentro_fuera': 'interno',\n",
        "                    'geometry': buffer_interno\n",
        "                })\n",
        "\n",
        "                # Agrego buffer externo\n",
        "                resultados.append({\n",
        "                    'id_parque': id_parque,\n",
        "                    'buffer_km': ancho,\n",
        "                    'dentro_fuera': 'externo',\n",
        "                    'geometry': buffer_externo\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\" Error procesando {id_parque} con {ancho}km: {e}\")\n",
        "                continue\n",
        "\n",
        "    return gpd.GeoDataFrame(resultados, crs=areas_protegidas.crs)\n",
        "\n"
      ],
      "metadata": {
        "id": "lcTvne1wS8yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# AHORA EXTRAER ESTAD√çSTICAS ZONALES\n",
        "\n",
        "def extraer_estadisticas_zonales(geometria, raster_data, raster_profile):\n",
        "    \"\"\"\n",
        "    Extrae estad√≠sticas de un r√°ster dentro de una geometr√≠a\n",
        "\n",
        "    Args:\n",
        "        geometria: Geometr√≠a para recortar el r√°ster\n",
        "        raster_data: Array del r√°ster\n",
        "        raster_profile: Metadatos del r√°ster\n",
        "\n",
        "    Returns:\n",
        "        dict con estad√≠sticas (media, mediana, std, n_pixeles)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Creo un dataset temporal en memoria\n",
        "        with rasterio.MemoryFile() as memfile:\n",
        "            with memfile.open(**raster_profile) as dataset:\n",
        "                dataset.write(raster_data, 1)\n",
        "\n",
        "                # Recorto el r√°ster con la geometr√≠a\n",
        "                masked_data, _ = mask(dataset, [geometria], crop=True, nodata=-9999)\n",
        "                masked_data = masked_data[0]  # Primera banda\n",
        "\n",
        "                # Elimino valores NoData\n",
        "                valid_data = masked_data[masked_data != -9999]\n",
        "\n",
        "                if len(valid_data) == 0:\n",
        "                    return {\n",
        "                        'media_tc': np.nan,\n",
        "                        'mediana_tc': np.nan,\n",
        "                        'sd_tc': np.nan,\n",
        "                        'n_pixeles': 0\n",
        "                    }\n",
        "\n",
        "                return {\n",
        "                    'media_tc': float(np.mean(valid_data)),\n",
        "                    'mediana_tc': float(np.median(valid_data)),\n",
        "                    'sd_tc': float(np.std(valid_data)),\n",
        "                    'n_pixeles': len(valid_data)\n",
        "                }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error en estad√≠sticas zonales: {e}\")\n",
        "        return {\n",
        "            'media_tc': np.nan,\n",
        "            'mediana_tc': np.nan,\n",
        "            'sd_tc': np.nan,\n",
        "            'n_pixeles': 0\n",
        "        }\n",
        "\n",
        "def procesar_estadisticas_todas_zonas(buffers_gdf, raster_data, raster_profile):\n",
        "    \"\"\"\n",
        "    Procesa estad√≠sticas zonales para todas las zonas de buffer\n",
        "    \"\"\"\n",
        "    print(\"\\n Extrayendo estad√≠sticas zonales...\")\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    for idx, row in buffers_gdf.iterrows():\n",
        "        print(f\"Procesando {row['id_parque']} - {row['buffer_km']}km - {row['dentro_fuera']}\")\n",
        "\n",
        "        stats = extraer_estadisticas_zonales(\n",
        "            row['geometry'], raster_data, raster_profile\n",
        "        )\n",
        "\n",
        "        resultado = {\n",
        "            'id_parque': row['id_parque'],\n",
        "            'buffer_km': row['buffer_km'],\n",
        "            'dentro_fuera': row['dentro_fuera'],\n",
        "            **stats\n",
        "        }\n",
        "\n",
        "        resultados.append(resultado)\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# LUEGO SE HAR√Å EL AN√ÅLISIS DE REGRESI√ìN\n",
        "\n",
        "def preparar_datos_regresion(df_estadisticas):\n",
        "    \"\"\"\n",
        "    Prepara los datos para la regresi√≥n binaria\n",
        "    \"\"\"\n",
        "    print(\"\\n Preparando datos para regresi√≥n...\")\n",
        "\n",
        "    # CreO variable de tratamiento D (1 = interno/dentro, 0 = externo/fuera)\n",
        "    df_regresion = df_estadisticas.copy()\n",
        "    df_regresion['D'] = (df_regresion['dentro_fuera'] == 'interno').astype(int)\n",
        "\n",
        "    # EliminO filas con valores faltantes\n",
        "    df_regresion = df_regresion.dropna(subset=['media_tc', 'n_pixeles'])\n",
        "    df_regresion = df_regresion[df_regresion['n_pixeles'] > 0]\n",
        "\n",
        "    print(f\"Datos para regresi√≥n: {len(df_regresion)} observaciones\")\n",
        "\n",
        "    return df_regresion\n",
        "\n",
        "def ejecutar_regresion(df_regresion):\n",
        "    \"\"\"\n",
        "    Ejecuta la regresi√≥n binaria ponderada\n",
        "    \"\"\"\n",
        "    print(\"\\n Ejecutando regresi√≥n...\")\n",
        "\n",
        "    # Las Variables\n",
        "    X = df_regresion[['D']].values\n",
        "    y = df_regresion['media_tc'].values\n",
        "    pesos = df_regresion['n_pixeles'].values\n",
        "\n",
        "    # Regresi√≥n lineal ponderada\n",
        "    modelo = LinearRegression()\n",
        "    modelo.fit(X, y, sample_weight=pesos)\n",
        "\n",
        "    # Predicciones\n",
        "    y_pred = modelo.predict(X)\n",
        "\n",
        "    # M√©tricas\n",
        "    r2 = r2_score(y, y_pred, sample_weight=pesos)\n",
        "\n",
        "    # Resultados\n",
        "    intercepto = modelo.intercept_\n",
        "    coef_D = modelo.coef_[0]\n",
        "\n",
        "    print(f\"Intercepto (Œ≤‚ÇÄ): {intercepto:.4f}\")\n",
        "    print(f\"Coeficiente D (Œ≤‚ÇÅ): {coef_D:.4f}\")\n",
        "    print(f\"R¬≤ ponderado: {r2:.4f}\")\n",
        "\n",
        "    # Interpretaci√≥n\n",
        "    print(f\"\\n Interpretaci√≥n:\")\n",
        "    print(f\"‚Ä¢ Cobertura forestal promedio FUERA de √°reas protegidas: {intercepto:.2f}%\")\n",
        "    print(f\"‚Ä¢ Diferencia DENTRO vs FUERA: {coef_D:.2f} puntos porcentuales\")\n",
        "\n",
        "    if coef_D > 0:\n",
        "        print(f\"‚Ä¢ Las √°reas protegidas tienen MAYOR cobertura forestal (+{coef_D:.2f}%)\")\n",
        "    else:\n",
        "        print(f\"‚Ä¢ Las √°reas protegidas tienen MENOR cobertura forestal ({coef_D:.2f}%)\")\n",
        "\n",
        "    return {\n",
        "        'modelo': modelo,\n",
        "        'intercepto': intercepto,\n",
        "        'coef_D': coef_D,\n",
        "        'r2': r2,\n",
        "        'n_obs': len(df_regresion)\n",
        "    }\n",
        "\n",
        "\n",
        "# LA FUNCI√ìN PRINCIPAL\n",
        "def analisis_completo():\n",
        "    \"\"\"\n",
        "    Ejecuta el an√°lisis completo de zonas de amortiguamiento\n",
        "    \"\"\"\n",
        "    print(\" INICIANDO AN√ÅLISIS DE ZONAS DE AMORTIGUAMIENTO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. CargO datos\n",
        "    areas_protegidas, forest_data, forest_profile = cargar_datos()\n",
        "\n",
        "    # 2. Defino anchos de buffer\n",
        "    anchos_km = [5, 10, 20, 25]\n",
        "\n",
        "    # 3. Genero los buffers\n",
        "    buffers_gdf = procesar_todos_buffers(areas_protegidas, anchos_km)\n",
        "    print(f\" Generados {len(buffers_gdf)} buffers\")\n",
        "\n",
        "    # 4. Extraigo  estad√≠sticas zonales\n",
        "    df_estadisticas = procesar_estadisticas_todas_zonas(\n",
        "        buffers_gdf, forest_data, forest_profile\n",
        "    )\n",
        "\n",
        "    # 5. Guardo resultados en CSV\n",
        "    archivo_csv = \"resultados_buffers.csv\"\n",
        "    df_estadisticas.to_csv(archivo_csv, index=False)\n",
        "    print(f\"‚úÖ Resultados guardados en: {archivo_csv}\")\n",
        "\n",
        "    # 6. Muestro la muestra de resultados...valga la redundancia\n",
        "    print(f\"\\n Muestra de resultados:\")\n",
        "    print(df_estadisticas.head(10).to_string())\n",
        "\n",
        "    # 7. An√°lisis de regresi√≥n\n",
        "    df_regresion = preparar_datos_regresion(df_estadisticas)\n",
        "    resultados_regresion = ejecutar_regresion(df_regresion)\n",
        "\n",
        "    # 8. Visualizaci√≥n\n",
        "    crear_visualizaciones(df_estadisticas, df_regresion)\n",
        "\n",
        "    print(\"\\n AN√ÅLISIS COMPLETADO\")\n",
        "    return df_estadisticas, resultados_regresion\n",
        "\n",
        "def crear_visualizaciones(df_estadisticas, df_regresion):\n",
        "    \"\"\"\n",
        "    Crea visualizaciones de los resultados\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "    # Gr√°fico 1: Cobertura promedio por buffer y tipo\n",
        "    ax1 = axes[0, 0]\n",
        "    df_pivot = df_estadisticas.pivot_table(\n",
        "        values='media_tc',\n",
        "        index='buffer_km',\n",
        "        columns='dentro_fuera',\n",
        "        aggfunc='mean'\n",
        "    )\n",
        "    df_pivot.plot(kind='bar', ax=ax1)\n",
        "    ax1.set_title('Cobertura Forestal Promedio por Zona')\n",
        "    ax1.set_ylabel('% Cobertura Arb√≥rea')\n",
        "    ax1.legend(title='Zona')\n",
        "\n",
        "    # Gr√°fico 2: Distribuci√≥n de cobertura\n",
        "    ax2 = axes[0, 1]\n",
        "    df_estadisticas[df_estadisticas['dentro_fuera'] == 'interno']['media_tc'].hist(\n",
        "        alpha=0.7, label='Interno', bins=20, ax=ax2\n",
        "    )\n",
        "    df_estadisticas[df_estadisticas['dentro_fuera'] == 'externo']['media_tc'].hist(\n",
        "        alpha=0.7, label='Externo', bins=20, ax=ax2\n",
        "    )\n",
        "    ax2.set_title('Distribuci√≥n de Cobertura Forestal')\n",
        "    ax2.set_xlabel('% Cobertura Arb√≥rea')\n",
        "    ax2.legend()\n",
        "\n",
        "    # Gr√°fico 3: Regresi√≥n\n",
        "    ax3 = axes[1, 0]\n",
        "    interno = df_regresion[df_regresion['D'] == 1]['media_tc']\n",
        "    externo = df_regresion[df_regresion['D'] == 0]['media_tc']\n",
        "\n",
        "    ax3.scatter([0] * len(externo), externo, alpha=0.6, label='Externo', s=30)\n",
        "    ax3.scatter([1] * len(interno), interno, alpha=0.6, label='Interno', s=30)\n",
        "\n",
        "    # L√≠nea de regresi√≥n\n",
        "    medias = [externo.mean(), interno.mean()]\n",
        "    ax3.plot([0, 1], medias, 'r-', linewidth=2, label='Regresi√≥n')\n",
        "\n",
        "    ax3.set_"
      ],
      "metadata": {
        "id": "fm0a9V1iUJW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INTENTO DEL CREDITO EXTRA\n"
      ],
      "metadata": {
        "id": "oHQE2uCmVSk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An√°lisis de Regresi√≥n Discontinua (RD) a Nivel de P√≠xel\n",
        "#CREDITO EXTRA\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rasterio.features import rasterize\n",
        "from rasterio.transform import rowcol, xy\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import seaborn as sns\n",
        "from shapely.geometry import Point\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# PREPARO DATOS Y M√ÅSCARAS\n",
        "\n",
        "def crear_datos_ejemplo():\n",
        "    \"\"\"\n",
        "    Crea datos de ejemplo para demostrar el an√°lisis RD\n",
        "    \"\"\"\n",
        "    print(\" Creando datos de ejemplo...\")\n",
        "\n",
        "    # Creo √°rea protegida de ejemplo\n",
        "    from shapely.geometry import Polygon\n",
        "\n",
        "    # √Årea protegida rectangular\n",
        "    area_protegida = Polygon([\n",
        "        (-75.2, -10.2),\n",
        "        (-74.8, -10.2),\n",
        "        (-74.8, -9.8),\n",
        "        (-75.2, -9.8),\n",
        "        (-75.2, -10.2)\n",
        "    ])\n",
        "\n",
        "    gdf = gpd.GeoDataFrame([{'id': 'PA_1', 'geometry': area_protegida}], crs='EPSG:4326')\n",
        "\n",
        "    # Creo r√°ster de cobertura forestal simulado\n",
        "    height, width = 400, 400\n",
        "\n",
        "    # Coordenadas del r√°ster\n",
        "    bounds = (-75.4, -10.4, -74.6, -9.6)\n",
        "    transform = rasterio.transform.from_bounds(*bounds, width, height)\n",
        "\n",
        "    # Simulo cobertura forestal con efecto de borde\n",
        "    np.random.seed(42)\n",
        "    x = np.linspace(-75.4, -74.6, width)\n",
        "    y = np.linspace(-10.4, -9.6, height)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "\n",
        "    # Creo efecto de gradiente hacia el √°rea protegida\n",
        "    center_x, center_y = -75.0, -10.0\n",
        "    distance_to_center = np.sqrt((X - center_x)**2 + (Y - center_y)**2)\n",
        "\n",
        "    # Cobertura base con efecto espacial\n",
        "    base_coverage = 60 + 30 * np.exp(-distance_to_center * 50)\n",
        "\n",
        "    # Agrego ruido\n",
        "    noise = np.random.normal(0, 10, (height, width))\n",
        "    forest_coverage = np.clip(base_coverage + noise, 0, 100)\n",
        "\n",
        "    profile = {\n",
        "        'driver': 'GTiff',\n",
        "        'dtype': 'float32',\n",
        "        'nodata': -9999,\n",
        "        'width': width,\n",
        "        'height': height,\n",
        "        'count': 1,\n",
        "        'crs': 'EPSG:4326',\n",
        "        'transform': transform\n",
        "    }\n",
        "\n",
        "    return gdf, forest_coverage.astype('float32'), profile\n",
        "\n",
        "def cargar_datos_reales(shapefile_path, raster_path):\n",
        "    \"\"\"\n",
        "    Carga datos reales si est√°n disponibles\n",
        "    \"\"\"\n",
        "    try:\n",
        "        gdf = gpd.read_file(shapefile_path)\n",
        "        with rasterio.open(raster_path) as src:\n",
        "            forest_data = src.read(1)\n",
        "            profile = src.profile\n",
        "        print(\" Datos reales cargados\")\n",
        "        return gdf, forest_data, profile\n",
        "    except:\n",
        "        print(\" Usando datos de ejemplo\")\n",
        "        return crear_datos_ejemplo()\n",
        "\n",
        "\n",
        "# CALCULO DISTANCIA AL L√çMITE\n",
        "\n",
        "def crear_mascara_area_protegida(gdf, raster_profile):\n",
        "    \"\"\"\n",
        "    Crea m√°scara binaria del √°rea protegida en el r√°ster\n",
        "    \"\"\"\n",
        "    print(\" Creando m√°scara de √°rea protegida...\")\n",
        "\n",
        "    # Rasterizo el pol√≠gono\n",
        "    shapes = [(geom, 1) for geom in gdf.geometry]\n",
        "\n",
        "    mask = rasterize(\n",
        "        shapes=shapes,\n",
        "        out_shape=(raster_profile['height'], raster_profile['width']),\n",
        "        transform=raster_profile['transform'],\n",
        "        fill=0,\n",
        "        dtype='uint8'\n",
        "    )\n",
        "\n",
        "    return mask.astype(bool)\n",
        "\n",
        "def calcular_distancia_al_limite(mask, transform):\n",
        "    \"\"\"\n",
        "    Calcula la distancia de cada p√≠xel al l√≠mite del √°rea protegida\n",
        "\n",
        "    Args:\n",
        "        mask: M√°scara binaria (True = dentro, False = fuera)\n",
        "        transform: Transformaci√≥n georreferenciada del r√°ster\n",
        "\n",
        "    Returns:\n",
        "        distance_array: Array con distancias (+ = interno, - = externo)\n",
        "    \"\"\"\n",
        "    print(\" Calculando distancias al l√≠mite...\")\n",
        "\n",
        "    # Distancia euclidiana desde el interior hacia el borde\n",
        "    dist_interior = distance_transform_edt(mask)\n",
        "\n",
        "    # Distancia euclidiana desde el exterior hacia el borde\n",
        "    dist_exterior = distance_transform_edt(~mask)\n",
        "\n",
        "    # Combino: positivo = interno, negativo = externo\n",
        "    distance_array = np.where(mask, dist_interior, -dist_exterior)\n",
        "\n",
        "    # Convierto p√≠xeles a metros (aproximaci√≥n)\n",
        "    pixel_size_degrees = abs(transform[0])  # Tama√±o de p√≠xel en grados\n",
        "    meters_per_degree = 111320  # Aproximadamente en el ecuador\n",
        "    pixel_size_meters = pixel_size_degrees * meters_per_degree\n",
        "\n",
        "    distance_meters = distance_array * pixel_size_meters\n",
        "\n",
        "    return distance_meters\n",
        "\n",
        "# PREPARO LOS DATOS A NIVEL DE P√çXEL\n",
        "\n",
        "def extraer_datos_buffer_25km(distance_array, forest_data, buffer_km=25):\n",
        "    \"\"\"\n",
        "    Extrae datos de p√≠xeles dentro del buffer de 25km del l√≠mite\n",
        "    \"\"\"\n",
        "    print(f\"üéØ Extrayendo p√≠xeles dentro de {buffer_km}km del l√≠mite...\")\n",
        "\n",
        "    buffer_meters = buffer_km * 1000\n",
        "\n",
        "    # M√°scara para p√≠xeles dentro del buffer\n",
        "    buffer_mask = np.abs(distance_array) <= buffer_meters\n",
        "\n",
        "    # Extraigo datos v√°lidos\n",
        "    valid_mask = buffer_mask & (forest_data != -9999) & (~np.isnan(forest_data))\n",
        "\n",
        "    distances = distance_array[valid_mask]\n",
        "    forest_values = forest_data[valid_mask]\n",
        "\n",
        "    # Creo DataFrame\n",
        "    df_pixels = pd.DataFrame({\n",
        "        'distance_m': distances,\n",
        "        'forest_cover': forest_values,\n",
        "        'inside': distances >= 0\n",
        "    })\n",
        "\n",
        "    print(f\"  Extra√≠dos {len(df_pixels):,} p√≠xeles v√°lidos\")\n",
        "    print(f\"   - Internos: {(df_pixels['inside']).sum():,}\")\n",
        "    print(f\"   - Externos: {(~df_pixels['inside']).sum():,}\")\n",
        "\n",
        "    return df_pixels\n",
        "\n",
        "# HAGO EL AN√ÅLISIS DE REGRESI√ìN DISCONTINUA\n",
        "\n",
        "def ejecutar_rd_analysis(df_pixels, bandwidth_m=5000, poly_degree=2):\n",
        "    \"\"\"\n",
        "    Ejecuta an√°lisis de Regresi√≥n Discontinua\n",
        "\n",
        "    Args:\n",
        "        df_pixels: DataFrame con datos de p√≠xeles\n",
        "        bandwidth_m: Ancho de banda alrededor del l√≠mite (metros)\n",
        "        poly_degree: Grado del polinomio para controles flexibles\n",
        "    \"\"\"\n",
        "    print(f\"\\n Ejecutando Regresi√≥n Discontinua...\")\n",
        "    print(f\"   - Ancho de banda: ¬±{bandwidth_m/1000:.1f}km\")\n",
        "    print(f\"   - Grado polinomial: {poly_degree}\")\n",
        "\n",
        "    # Filtro datos dentro del ancho de banda\n",
        "    df_rd = df_pixels[np.abs(df_pixels['distance_m']) <= bandwidth_m].copy()\n",
        "\n",
        "    if len(df_rd) == 0:\n",
        "        print(\" No hay datos dentro del ancho de banda\")\n",
        "        return None\n",
        "\n",
        "    # Normalizo las distancia (dividir por 1000 para trabajar en km)\n",
        "    df_rd['distance_km'] = df_rd['distance_m'] / 1000\n",
        "    df_rd['treatment'] = df_rd['inside'].astype(int)\n",
        "\n",
        "    # Centrar distancia en el l√≠mite\n",
        "    df_rd['distance_centered'] = df_rd['distance_km']\n",
        "\n",
        "    # Creo variables polinomiales\n",
        "    X_vars = []\n",
        "\n",
        "    # Variable de tratamiento (discontinuidad)\n",
        "    X_vars.append(df_rd['treatment'].values.reshape(-1, 1))\n",
        "\n",
        "    # Controles polinomiales de distancia\n",
        "    for degree in range(1, poly_degree + 1):\n",
        "        X_vars.append((df_rd['distance_centered'] ** degree).values.reshape(-1, 1))\n",
        "\n",
        "    # Interacciones tratamiento √ó distancia\n",
        "    for degree in range(1, poly_degree + 1):\n",
        "        interaction = (df_rd['treatment'] * (df_rd['distance_centered'] ** degree)).values.reshape(-1, 1)\n",
        "        X_vars.append(interaction)\n",
        "\n",
        "    # Combino todas las variables\n",
        "    X = np.hstack(X_vars)\n",
        "    y = df_rd['forest_cover'].values\n",
        "\n",
        "    # Regresi√≥n\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predicciones\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # El coeficiente de tratamiento es el primero\n",
        "    rd_effect = model.coef_[0]\n",
        "    intercept = model.intercept_\n",
        "\n",
        "    # R¬≤\n",
        "    ss_res = np.sum((y - y_pred) ** 2)\n",
        "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    # Estad√≠sticas descriptivas\n",
        "    stats = {\n",
        "        'n_total': len(df_rd),\n",
        "        'n_inside': df_rd['treatment'].sum(),\n",
        "        'n_outside': len(df_rd) - df_rd['treatment'].sum(),\n",
        "        'mean_inside': df_rd[df_rd['inside']]['forest_cover'].mean(),\n",
        "        'mean_outside': df_rd[~df_rd['inside']]['forest_cover'].mean(),\n",
        "        'rd_effect': rd_effect,\n",
        "        'intercept': intercept,\n",
        "        'r2': r2,\n",
        "        'bandwidth_km': bandwidth_m / 1000\n",
        "    }\n",
        "\n",
        "    print(f\"\\n RESULTADOS DE REGRESI√ìN DISCONTINUA:\")\n",
        "    print(f\"   ‚Ä¢ Observaciones: {stats['n_total']:,}\")\n",
        "    print(f\"   ‚Ä¢ Efecto RD (Œ≤‚ÇÅ): {rd_effect:.3f} puntos porcentuales\")\n",
        "    print(f\"   ‚Ä¢ Cobertura en el l√≠mite (exterior): {intercept:.2f}%\")\n",
        "    print(f\"   ‚Ä¢ R¬≤: {r2:.3f}\")\n",
        "    print(f\"   ‚Ä¢ Media interna: {stats['mean_inside']:.2f}%\")\n",
        "    print(f\"   ‚Ä¢ Media externa: {stats['mean_outside']:.2f}%\")\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'data': df_rd,\n",
        "        'stats': stats,\n",
        "        'X': X,\n",
        "        'y': y,\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "\n",
        "# LUEGO LAS VISUALIZACIONES\n",
        "\n",
        "def crear_graficos_rd(rd_results, df_pixels):\n",
        "    \"\"\"\n",
        "    Crea gr√°ficos de Regresi√≥n Discontinua\n",
        "    \"\"\"\n",
        "    print(\"\\n Generando gr√°ficos...\")\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "    df_rd = rd_results['data']\n",
        "    stats = rd_results['stats']\n",
        "\n",
        "    # Gr√°fico 1: RD Plot Principal\n",
        "    ax1 = axes[0, 0]\n",
        "\n",
        "    # Datos agrupados en bins para visualizaci√≥n\n",
        "    bins_inside = np.linspace(0, stats['bandwidth_km'], 20)\n",
        "    bins_outside = np.linspace(-stats['bandwidth_km'], 0, 20)\n",
        "\n",
        "    # Calculo medias por bin\n",
        "    def bin_means(distances, values, bins):\n",
        "        bin_centers = []\n",
        "        bin_means_vals = []\n",
        "        for i in range(len(bins)-1):\n",
        "            mask = (distances >= bins[i]) & (distances < bins[i+1])\n",
        "            if mask.sum() > 0:\n",
        "                bin_centers.append((bins[i] + bins[i+1]) / 2)\n",
        "                bin_means_vals.append(values[mask].mean())\n",
        "        return np.array(bin_centers), np.array(bin_means_vals)\n",
        "\n",
        "    # Datos internos\n",
        "    inside_data = df_rd[df_rd['inside']]\n",
        "    if len(inside_data) > 0:\n",
        "        bin_centers_in, bin_means_in = bin_means(\n",
        "            inside_data['distance_km'], inside_data['forest_cover'], bins_inside\n",
        "        )\n",
        "        ax1.scatter(bin_centers_in, bin_means_in, c='green', s=50, alpha=0.7, label='Interno')\n",
        "\n",
        "    # Datos externos\n",
        "    outside_data = df_rd[~df_rd['inside']]\n",
        "    if len(outside_data) > 0:\n",
        "        bin_centers_out, bin_means_out = bin_means(\n",
        "            outside_data['distance_km'], outside_data['forest_cover'], bins_outside\n",
        "        )\n",
        "        ax1.scatter(bin_centers_out, bin_means_out, c='red', s=50, alpha=0.7, label='Externo')\n",
        "\n",
        "    # L√≠nea de regresi√≥n\n",
        "    x_smooth = np.linspace(-stats['bandwidth_km'], stats['bandwidth_km'], 100)\n",
        "\n",
        "    # Predicci√≥n para visualizaci√≥n (simplificada)\n",
        "    y_left = stats['intercept'] + 0 * x_smooth[x_smooth < 0]  # Lado externo\n",
        "    y_right = stats['intercept'] + stats['rd_effect'] + 0 * x_smooth[x_smooth >= 0]  # Lado interno\n",
        "\n",
        "    if len(x_smooth[x_smooth < 0]) > 0:\n",
        "        ax1.plot(x_smooth[x_smooth < 0], y_left, 'r-', linewidth=2, alpha=0.8)\n",
        "    if len(x_smooth[x_smooth >= 0]) > 0:\n",
        "        ax1.plot(x_smooth[x_smooth >= 0], y_right, 'g-', linewidth=2, alpha=0.8)\n",
        "\n",
        "    # L√≠nea vertical en el l√≠mite\n",
        "    ax1.axvline(x=0, color='black', linestyle='--', alpha=0.5, label='L√≠mite AP')\n",
        "\n",
        "    ax1.set_xlabel('Distancia al L√≠mite (km)')\n",
        "    ax1.set_ylabel('Cobertura Forestal (%)')\n",
        "    ax1.set_title(f'Regresi√≥n Discontinua\\nEfecto: {stats[\"rd_effect\"]:.2f} pp')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Gr√°fico 2: Distribuci√≥n de distancias\n",
        "    ax2 = axes[0, 1]\n",
        "    df_rd['distance_km'].hist(bins=30, alpha=0.7, ax=ax2)\n",
        "    ax2.axvline(x=0, color='red', linestyle='--', label='L√≠mite')\n",
        "    ax2.set_xlabel('Distancia al L√≠mite (km)')\n",
        "    ax2.set_ylabel('N√∫mero de P√≠xeles')\n",
        "    ax2.set_title('Distribuci√≥n de Distancias')\n",
        "    ax2.legend()\n",
        "\n",
        "    # Gr√°fico 3: Cobertura vs Distancia (scatter completo)\n",
        "    ax3 = axes[1, 0]\n",
        "\n",
        "    # Submuestreo para visualizaci√≥n si hay muchos puntos\n",
        "    if len(df_rd) > 5000:\n",
        "        df_sample = df_rd.sample(5000, random_state=42)\n",
        "    else:\n",
        "        df_sample = df_rd\n",
        "\n",
        "    inside_sample = df_sample[df_sample['inside']]\n",
        "    outside_sample = df_sample[~df_sample['inside']]\n",
        "\n",
        "    ax3.scatter(outside_sample['distance_km'], outside_sample['forest_cover'],\n",
        "               c='red', alpha=0.3, s=1, label='Externo')\n",
        "    ax3.scatter(inside_sample['distance_km'], inside_sample['forest_cover'],\n",
        "               c='green', alpha=0.3, s=1, label='Interno')\n",
        "\n",
        "    ax3.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
        "    ax3.set_xlabel('Distancia al L√≠mite (km)')\n",
        "    ax3.set_ylabel('Cobertura Forestal (%)')\n",
        "    ax3.set_title('Datos Individuales por P√≠xel')\n",
        "    ax3.legend()\n",
        "\n",
        "    # Gr√°fico 4: Comparaci√≥n de medias\n",
        "    ax4 = axes[1, 1]\n",
        "\n",
        "    means = [stats['mean_outside'], stats['mean_inside']]\n",
        "    labels = ['Externo', 'Interno']\n",
        "    colors = ['red', 'green']\n",
        "\n",
        "    bars = ax4.bar(labels, means, color=colors, alpha=0.7)\n",
        "    ax4.set_ylabel('Cobertura Forestal Promedio (%)')\n",
        "    ax4.set_title('Comparaci√≥n de Medias')\n",
        "\n",
        "    # Agrego valores en las barras\n",
        "    for bar, mean in zip(bars, means):\n",
        "        height = bar.get_height()\n",
        "        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                f'{mean:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "    # L√≠nea de diferencia\n",
        "    ax4.annotate('', xy=(0.1, stats['mean_outside']), xytext=(0.9, stats['mean_inside']),\n",
        "                arrowprops=dict(arrowstyle='<->', color='blue', lw=2))\n",
        "    ax4.text(0.5, (stats['mean_inside'] + stats['mean_outside'])/2 + 1,\n",
        "             f'Œî = {stats[\"rd_effect\"]:.2f} pp', ha='center', color='blue', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('rd_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# LA FUNCI√ìN PRINCIPAL\n",
        "\n",
        "def analisis_rd_completo(shapefile_path=None, raster_path=None):\n",
        "    \"\"\"\n",
        "    Ejecuta el an√°lisis completo de Regresi√≥n Discontinua\n",
        "    \"\"\"\n",
        "    print(\" AN√ÅLISIS DE REGRESI√ìN DISCONTINUA - NIVEL DE P√çXEL\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. Cargo datos\n",
        "    if shapefile_path and raster_path:\n",
        "        gdf, forest_data, profile = cargar_datos_reales(shapefile_path, raster_path)\n",
        "    else:\n",
        "        gdf, forest_data, profile = crear_datos_ejemplo()\n",
        "\n",
        "    # 2. Creo m√°scara de √°rea protegida\n",
        "    mask = crear_mascara_area_protegida(gdf, profile)\n",
        "\n",
        "    # 3. Calculo distancias al l√≠mite\n",
        "    distance_array = calcular_distancia_al_limite(mask, profile['transform'])\n",
        "\n",
        "    # 4. Extraigo datos en buffer de 25km\n",
        "    df_pixels = extraer_datos_buffer_25km(distance_array, forest_data, buffer_km=25)\n",
        "\n",
        "    # 5. An√°lisis RD con diferentes anchos de banda\n",
        "    print(f\"\\nüî¨ PROBANDO DIFERENTES ANCHOS DE BANDA:\")\n",
        "\n",
        "    bandwidths = [2, 5, 10, 15]  # km\n",
        "    rd_results_list = []\n",
        "\n",
        "    for bw_km in bandwidths:\n",
        "        print(f\"\\n--- Ancho de banda: {bw_km}km ---\")\n",
        "        rd_result = ejecutar_rd_analysis(df_pixels, bandwidth_m=bw_km*1000, poly_degree=2)\n",
        "        if rd_result:\n",
        "            rd_results_list.append({\n",
        "                'bandwidth': bw_km,\n",
        "                'effect': rd_result['stats']['rd_effect'],\n",
        "                'r2': rd_result['stats']['r2'],\n",
        "                'n_obs': rd_result['stats']['n_total']\n",
        "            })\n",
        "\n",
        "    # 6. Uso el ancho de banda √≥ptimo (5km por defecto)\n",
        "    rd_final = ejecutar_rd_analysis(df_pixels, bandwidth_m=5000, poly_degree=2)\n",
        "\n",
        "    # 7. Creo visualizaciones\n",
        "    if rd_final:\n",
        "        crear_graficos_rd(rd_final, df_pixels)\n",
        "\n",
        "    # 8. Resumen de resultados\n",
        "    print(f\"\\n RESUMEN DE RESULTADOS:\")\n",
        "    print(\"-\" * 40)\n",
        "    for result in rd_results_list:\n",
        "        print(f\"BW={result['bandwidth']:2d}km: Efecto={result['effect']:+6.2f}pp, \"\n",
        "              f\"R¬≤={result['r2']:.3f}, N={result['n_obs']:,}\")\n",
        "\n",
        "    return {\n",
        "        'distance_array': distance_array,\n",
        "        'df_pixels': df_pixels,\n",
        "        'rd_results': rd_final,\n",
        "        'sensitivity': rd_results_list,\n",
        "        'mask': mask\n",
        "    }\n",
        "\n",
        "# EJECUTO EL AN√ÅLISIS\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejecutar con datos de ejemplo\n",
        "    resultados = analisis_rd_completo()\n",
        "\n",
        "    # Para usar tus propios datos, descomenta y ajusta:\n",
        "    # resultados = analisis_rd_completo(\n",
        "    #     shapefile_path=\"areas_protegidas.shp\",\n",
        "    #     raster_path=\"cobertura_forestal.tif\"\n",
        "    # )"
      ],
      "metadata": {
        "id": "-VYrKn7ZVYoB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}